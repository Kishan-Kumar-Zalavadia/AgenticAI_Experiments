{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7LlQbva8F7gC2EbV3pn/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kishan-Kumar-Zalavadia/AgenticAI_Experiments/blob/main/2_First_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Simple AI Agent\n",
        "\n",
        "## *The agent can list files in a given directory, read their content, and answer questions about them.*\n",
        "\n",
        "\n",
        "> If you wish to see the agent code, it's at the end.\n",
        "\n"
      ],
      "metadata": {
        "id": "wAs4EolBS1Zr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This agent will be able to list files in a directory, read their content, and answer questions about them. We’ll break down the agent loop—how it receives input, decides on actions, executes them, and updates its memory—step by step.\n"
      ],
      "metadata": {
        "id": "MNq8DlHUS7Qa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Agent Loop in Python\n",
        "\n",
        "The agent loop is the backbone of our AI agent, enabling it to perform tasks by combining response generation, action execution, and memory updates in an iterative process. This section focuses on how the agent loop works and its role in making the agent dynamic and adaptive.\n",
        "\n",
        "1. **Construct Prompt**: Combine the agent’s memory, user input, and system rules into a single prompt. This ensures the LLM has all the context it needs to decide on the next action, maintaining continuity across iterations.\n",
        "\n",
        "3. **Generate Response**: Send the constructed prompt to the LLM and retrieve a response. This response will guide the agent’s next step by providing instructions in a structured format.\n",
        "\n",
        "4. **Parse Response**: Extract the intended action and its parameters from the LLM’s output. The response must adhere to a predefined structure (e.g., JSON format) to ensure it can be interpreted correctly.\n",
        "\n",
        "5. **Execute Action**: Use the extracted action and its parameters to perform the requested task with the appropriate tool. This could involve listing files, reading content, or printing a message.\n",
        "\n",
        "6. **Convert Result to String**: Format the result of the executed action into a string. This allows the agent to store the result in its memory and provide clear feedback to the user or itself.\n",
        "\n",
        "7. **Continue Loop?**: Evaluate whether the loop should continue based on the current action and results. The loop may terminate if a “terminate” action is specified or if the agent has completed the task.\n",
        "\n",
        "The agent iterates through this loop, refining its behavior and adapting its actions until it reaches a stopping condition. This process is what enables the agent to interact dynamically and respond intelligently to tasks.\n",
        "\n",
        "Here’s how these steps come together in code:\n",
        "\n",
        "```\n",
        "# The Agent Loop\n",
        "while iterations < max_iterations:\n",
        "\n",
        "    # 1. Construct prompt: Combine agent rules with memory\n",
        "    prompt = agent_rules + memory\n",
        "\n",
        "    # 2. Generate response from LLM\n",
        "    print(\"Agent thinking...\")\n",
        "    response = generate_response(prompt)\n",
        "    print(f\"Agent response: {response}\")\n",
        "\n",
        "    # 3. Parse response to determine action\n",
        "    action = parse_action(response)\n",
        "\n",
        "    result = \"Action executed\"\n",
        "\n",
        "    if action[\"tool_name\"] == \"list_files\":\n",
        "        result = {\"result\":list_files()}\n",
        "    elif action[\"tool_name\"] == \"read_file\":\n",
        "        result = {\"result\":read_file(action[\"args\"][\"file_name\"])}\n",
        "    elif action[\"tool_name\"] == \"error\":\n",
        "        result = {\"error\":action[\"args\"][\"message\"]}\n",
        "    elif action[\"tool_name\"] == \"terminate\":\n",
        "        print(action[\"args\"][\"message\"])\n",
        "        break\n",
        "    else:\n",
        "        result = {\"error\":\"Unknown action: \"+action[\"tool_name\"]}\n",
        "\n",
        "    print(f\"Action result: {result}\")\n",
        "\n",
        "    # 5. Update memory with response and results\n",
        "    memory.extend([\n",
        "        {\"role\": \"assistant\", \"content\": response},\n",
        "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "    ])\n",
        "\n",
        "    # 6. Check termination condition\n",
        "    if action[\"tool_name\"] == \"terminate\":\n",
        "        break\n",
        "\n",
        "    iterations += 1\n",
        "  ```"
      ],
      "metadata": {
        "id": "QFO8xcGDTCVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Constructing the Agent Prompt**\n",
        "\n",
        "The prompt is created by appending the agent’s rules (system message) to the current memory of interactions. Part of the memory is a descripton of the task that the agent should perofrm. This ensures the agent is always aware of its tools and constraints while also remembering past actions.\n",
        "\n",
        "```\n",
        "prompt = agent_rules + memory\n",
        "```\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "- **agent_rules**: This contains the predefined system instructions, ensuring the agent behaves within its defined constraints and understands its tools.\n",
        "- **memory**: This is a record of all past interactions, including user input, the agent’s responses, and the results of executed actions.\n",
        "\n",
        "\n",
        "By constructing the prompt this way, the agent retains continuity across iterations, ensuring it can adapt its behavior based on previous actions and results. The memory tells it what just happened, what happened in the past, and informs its decision of the next action.\n",
        "\n",
        "## Agent Rules: Defining the Agent’s Behavior\n",
        "\n",
        "Before the agent begins its loop, it must have a clear set of rules that define its behavior, capabilities, and constraints. These agent rules are specified in the system message and play a critical role in ensuring the agent interacts predictably and within its defined boundaries.\n",
        "\n",
        "**How it works in code:**\n",
        "\n",
        "The agent_rules are written as a system message that instructs the LLM on how the agent should behave, what tools it has available, and how to format its responses. These rules are included at the start of the prompt for every iteration.\n",
        "\n",
        "## Agent Rules: Defining the Agent’s Behavior\n",
        "\n",
        "Before the agent begins its loop, it must have a clear set of rules that define its behavior, capabilities, and constraints. These agent rules are specified in the system message and play a critical role in ensuring the agent interacts predictably and within its defined boundaries.\n",
        "\n",
        "```\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "Available tools:\n",
        "- list_files() -> List[str]: List all files in the current directory.\n",
        "- read_file(file_name: str) -> str: Read the content of a file.\n",
        "- terminate(message: str): End the agent loop and print a summary to the user.\n",
        "\n",
        "If a user asks about files, list them before reading.\n",
        "\n",
        "Every response MUST have an action.\n",
        "Respond in this format:\n",
        "\n",
        "```action\n",
        "{\n",
        "    \"tool_name\": \"insert tool_name\",\n",
        "    \"args\": {...fill in any required arguments here...}\n",
        "}\n",
        "```\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "- **Role of system messages**: The system role in the messages list is used to establish ground rules for the agent. This ensures the LLM understands what it can do and how it should behave throughout the session.\n",
        "\n",
        "- **Tools description**: The agent rules explicitly list the tools the agent can use, providing a structured interface for interaction with the environment.\n",
        "\n",
        "- **Output format**: The rules enforce a standardized output format (\"```action {...}\"), which makes parsing and executing actions easier and less error-prone.\n",
        "\n",
        "\n",
        "Each of the “tools” in the system prompt correspond to a function in the code. The agent is going to choose what function to execute and when. Moreover, it is going to decide the parameters that are provided to the functions.\n",
        "\n",
        "The agent is not creating the functions at this point; it is orchestrating their behavior. This means that the logic for how each tool operates is predefined in the code, and the agent focuses on selecting the right tool for the job and providing the correct input to that tool.\n",
        "\n",
        "Because agents can adapt as the loop progresses, they can dynamically decide which tool to use based on the current context and task requirements. This ability allows the agent to adjust its behavior as new information becomes available, making it more flexible and responsive to the user’s input.\n",
        "\n",
        "For example, if the user asks the agent to read the contents of a specific file, the agent will first use the list_files tool to identify the available files. Then, based on the result, it will determine whether to proceed with the read_file tool or respond with an error if the file does not exist. The agent evaluates each step iteratively, ensuring its actions are informed by the current state of the environment.\n",
        "\n",
        "This orchestration process, driven by the agent rules and the tools available, showcases the power of combining pre-defined functions with adaptive decision-making. By allowing the agent to focus on what to do rather than how to do it, we create a system that leverages the LLM for high-level reasoning while relying on well-defined code for execution.\n",
        "\n",
        "This separation of reasoning and execution is what makes the agent loop so powerful—it creates a modular, extensible framework that can handle increasingly complex tasks without rewriting the underlying tools.\n",
        "\n",
        "Additionally, the agent loop eliminates much of the “glue code” traditionally required to tie these fundamental functions together. Instead of hardcoding workflows, the agent dynamically decides the sequence of actions needed to achieve a task, effectively realizing a program on top of its components. This dynamic nature enables the agent to combine its tools in ways that would typically require custom logic, making it far more versatile and capable of addressing a broader range of use cases without additional development overhead.\n",
        "\n",
        "**Example in practice:**\n",
        "\n",
        "If the user asks, “What files are here?”, the agent rules guide the LLM to respond with something like:\n",
        "\n",
        "```\n",
        "{\"tool_name\": \"list_files\", \"args\": {}}\n",
        "```\n",
        "\n",
        "This response ensures the agent’s next step is both predictable and executable within its predefined constraints.\n",
        "\n",
        "### How agent_rules integrate with the loop:\n",
        "\n",
        "The agent_rules are combined with the memory in Step 1: Construct Prompt to form the input for the LLM. This guarantees that the agent always has access to its instructions and tools at every iteration. We will discuss the memory in more detail later.\n",
        "\n",
        "This step prepares the input for the LLM by combining the system rules and the memory of the agent’s previous interactions. The goal is to give the LLM all the necessary context for generating the next action.\n",
        "\n",
        "**Example in practice:**\n",
        "\n",
        "If the user asks, “What files are in this directory?”, the memory might look like this:\n",
        "\n",
        "```\n",
        "memory = [\n",
        "    {\"role\": \"user\", \"content\": \"What files are in this directory?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"```action\\n{\\\"tool_name\\\":\\\"list_files\\\",\\\"args\\\":{}}\\n```\"},\n",
        "    {\"role\": \"user\", \"content\": \"[\\\"file1.txt\\\", \\\"file2.txt\\\"]\"}\n",
        "]\n",
        "```\n",
        "\n",
        "Adding agent_rules ensures the LLM understands what tools it can use to continue interacting.\n",
        "\n"
      ],
      "metadata": {
        "id": "ekSRwJnbWaWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Generate Response**\n",
        "\n",
        "After constructing the prompt, the agent sends it to the LLM to receive a response. This response will define the next action for the agent to execute.\n",
        "\n",
        "**Code snippet:**\n",
        "\n",
        "```\n",
        "response = generate_response(prompt)\n",
        "```\n",
        "\n",
        "**Explanation**:\n",
        "\n",
        "The generate_response function uses the LiteLLM library to send the prompt to the LLM and retrieve its response. The response typically includes a structured action that the agent will parse and execute in the next steps. This is where the LLM decides what action the agent should take, based on the provided context and rules.\n",
        "\n",
        "Once the Agent has generated a response, we need to interface the agent with the environment. This involves figuring out how the Agent’s response corresponds to an action in the environment. Once the correct action is determined, the interface can execute the action and later provide the Agent feedback on the result of the action."
      ],
      "metadata": {
        "id": "j3Sio0Z7X7p9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Parse the Response**\n",
        "\n",
        "After generating a response, the next step is to extract the intended action and its parameters from the LLM’s output. The response is expected to follow a predefined structure, such as a JSON format encapsulated within a markdown code block. This structure ensures the action can be parsed and executed without ambiguity.\n",
        "\n",
        "In the code, this is accomplished by locating and extracting the content between the ```action markers. If the response does not include a valid action block, the agent defaults to a termination action, returning the raw response as the message:\n",
        "\n",
        "```\n",
        "def parse_action(response: str) -> Dict:\n",
        "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
        "    try:\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "        response_json = json.loads(response)\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "```\n",
        "This parsing step is critical to ensuring the response is actionable. It provides a structured output, such as:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"tool_name\": \"list_files\",\n",
        "    \"args\": {}\n",
        "}\n",
        "```\n",
        "\n",
        "By breaking down the LLM’s output into tool_name and args, the agent can precisely determine the next action and its inputs.\n",
        "\n",
        "If the LLM response does not contain a valid action block, the agent defaults to an error message, prompting the LLM to provide a valid JSON tool invocation. The error message appears to have come from the “user”. This fallback mechanism ensures the agent can recover if it starts outputting invalid responses that aren’t in the desired format."
      ],
      "metadata": {
        "id": "DQKwKZaiYRKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Execute the Action**\n",
        "\n",
        "Once the response is parsed, the agent uses the extracted tool_name and args to execute the corresponding function. Each predefined tool in the system instructions corresponds to a specific function in the code, enabling the agent to interact with its environment.\n",
        "\n",
        "The execution logic involves mapping the tool_name to the appropriate function and passing the provided arguments:\n",
        "\n",
        "```\n",
        "if action[\"tool_name\"] == \"list_files\":\n",
        "    result = {\"result\": list_files()}\n",
        "elif action[\"tool_name\"] == \"read_file\":\n",
        "    result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
        "elif action[\"tool_name\"] == \"error\":\n",
        "    result = {\"error\": action[\"args\"][\"message\"]}\n",
        "elif action[\"tool_name\"] == \"terminate\":\n",
        "    print(action[\"args\"][\"message\"])\n",
        "    break\n",
        "else:\n",
        "    result = {\"error\":\"Unknown action: \"+action[\"tool_name\"]}\n",
        "```\n",
        "\n",
        "For example, if the action specifies tool_name as list_files with empty args, the list_files() function is called, and the agent returns the list of files in the directory. Similarly, a read_file action extracts the filename from the arguments and retrieves its content.\n",
        "\n",
        "The execution step is the point where the agent performs tangible work, such as interacting with files or printing messages to the console. It bridges the decision-making process with concrete results that feed back into the agent’s memory for subsequent iterations."
      ],
      "metadata": {
        "id": "ntve_vGlY1CT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Update the Agent’s Memory**\n",
        "\n",
        "After executing an action, the agent updates its memory with the results. Memory serves as the agent’s record of what has happened during the interaction, including user requests, the actions performed, and their outcomes. By appending this information to the memory, the agent retains context, enabling it to make more informed decisions in future iterations.\n",
        "\n",
        "In the code, memory is updated by extending it with both the LLM’s response (representing the agent’s intention) and the result of the executed action:\n",
        "\n",
        "```\n",
        "memory.extend([\n",
        "    {\"role\": \"assistant\", \"content\": response},\n",
        "    {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "])\n",
        "```\n",
        "\n",
        "**How This Works:**\n",
        "\n",
        "- The assistant role captures the structured response generated by the LLM.\n",
        "- The user role captures the feedback in the form of the action result, ensuring that the LLM has a clear understanding of what happened after the action was performed. The results of actions are always communicated back to the LLM with the “user” role.\n",
        "\n",
        "By keeping a running history of these exchanges, the agent maintains continuity, allowing it to refine its behavior dynamically as the memory grows and track the status of its work."
      ],
      "metadata": {
        "id": "eClxR2p6ZQcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 6: Decide Whether to Continue**\n",
        "\n",
        "The final step in each iteration of the agent loop is determining whether to continue or terminate. This decision is based on the action executed and the state of the task at hand. If the parsed action specifies terminate, or if a predefined condition (e.g., maximum iterations) is met, the agent ends its loop.\n",
        "\n",
        "In the code, this is implemented as a simple conditional check:\n",
        "\n",
        "```\n",
        "if action[\"tool_name\"] == \"terminate\":\n",
        "    print(action[\"args\"][\"message\"])\n",
        "    break\n",
        "```\n",
        "\n",
        "If the action specifies a termination, the loop exits, and the agent provides a closing message defined in the terminate action’s arguments. If no termination is triggered, the agent loops back to process the next user request or continue its task.\n",
        "\n",
        "## Example: Iterative Adaptation\n",
        "\n",
        "Imagine the agent is tasked with reading a file but encounters a missing filename in the initial request.\n",
        "\n",
        "1. In the first iteration, it executes list_files to retrieve the available files.\n",
        "2. Based on the memory of this result, it refines its next action, prompting the user to select a specific file.\n",
        "3. This iterative process continues until the task is completed or the agent determines that no further actions are required.\n",
        "\n",
        "Each loop iteration, the agent can look back at its memory to decide if it has completed the overall task. The memory is a critical part of deciding if the agent should continue or terminate. By deciding whether to continue at each step, the agent balances its ability to dynamically adapt to new information with the need to eventually conclude its task. The agent can also be instructed on when to terminate the loop, such as if more than two errors are encountered or if a specific condition is met."
      ],
      "metadata": {
        "id": "bnrh7RpNZsIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "6miW7ocmS1Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from litellm import completion\n",
        "from google.colab import userdata\n",
        "\n",
        "# -----------------------------\n",
        "# Setup API Key\n",
        "# -----------------------------\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# LLM Response Generator\n",
        "# -----------------------------\n",
        "def generate_response(messages):\n",
        "    \"\"\"Generate a response from the LLM using LiteLLM.\"\"\"\n",
        "    response = completion(\n",
        "        model=\"groq/llama-3.3-70b-versatile\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Helper Functions (Tools)\n",
        "# -----------------------------\n",
        "def list_files(folder_name):\n",
        "    \"\"\"List files inside the given folder.\"\"\"\n",
        "    try:\n",
        "        if not os.path.isdir(folder_name):\n",
        "            return [f\"Error: Folder '{folder_name}' not found.\"]\n",
        "        return os.listdir(folder_name)\n",
        "    except Exception as e:\n",
        "        return [f\"Error listing files: {str(e)}\"]\n",
        "\n",
        "\n",
        "def read_file(folder_name, file_name):\n",
        "    \"\"\"Read content of a file inside the given folder.\"\"\"\n",
        "    try:\n",
        "        file_path = os.path.join(folder_name, file_name)\n",
        "        if not os.path.exists(file_path):\n",
        "            return f\"Error: File '{file_name}' not found in folder '{folder_name}'.\"\n",
        "        with open(file_path, 'r') as f:\n",
        "            return f.read()\n",
        "    except Exception as e:\n",
        "        return f\"Error reading file {file_name}: {str(e)}\"\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Utility Functions\n",
        "# -----------------------------\n",
        "def extract_markdown_block(text, block_name):\n",
        "    \"\"\"Extract content between code fences like ```action ... ```.\"\"\"\n",
        "    start_token = f\"```{block_name}\"\n",
        "    end_token = \"```\"\n",
        "    if start_token in text:\n",
        "        start = text.index(start_token) + len(start_token)\n",
        "        end = text.index(end_token, start)\n",
        "        return text[start:end].strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "def parse_action(response):\n",
        "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
        "    try:\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "        response_json = json.loads(response)\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"Response missing 'tool_name' or 'args'.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response format.\"}}\n",
        "    except Exception as e:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": f\"Parsing error: {str(e)}\"}}\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Define Agent Rules\n",
        "# -----------------------------\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "Available tools:\n",
        "- list_files(folder_name: str) -> List[str]: List all files inside the given folder.\n",
        "- read_file(folder_name: str, file_name: str) -> str: Read the content of a file inside the given folder.\n",
        "- terminate(message: str): End the agent loop and print a summary to the user.\n",
        "\n",
        "If a user asks about files, list them before reading.\n",
        "\n",
        "Every response MUST have an action.\n",
        "Respond in this format:\n",
        "\n",
        "```action\n",
        "{\n",
        "    \"tool_name\": \"insert_tool_name_here\",\n",
        "    \"args\": {...fill in required arguments...}\n",
        "}\n",
        "\"\"\"\n",
        "}]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main Agent Loop\n",
        "# -----------------------------\n",
        "def run_agent(folder_name, user_input, max_iterations=5):\n",
        "    memory = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": f\"You are a file interaction agent. You can only access files inside the folder '{folder_name}'. \"\n",
        "                   f\"Whenever you output an action, always include 'folder_name': '{folder_name}' instead of '.'.\"\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": user_input}\n",
        "]\n",
        "    iterations = 0\n",
        "\n",
        "    while iterations < max_iterations:\n",
        "        prompt = agent_rules + memory\n",
        "        print(\"\\nAgent thinking...\")\n",
        "        response = generate_response(prompt)\n",
        "        print(f\"\\n🧠 Agent Response:\\n{response}\")\n",
        "        action = parse_action(response)\n",
        "        print(f\"\\n🧩 Parsed Action: {action}\")\n",
        "\n",
        "        if action[\"tool_name\"] == \"list_files\":\n",
        "            result = {\"result\": list_files(folder_name)}\n",
        "        elif action[\"tool_name\"] == \"read_file\":\n",
        "            result = {\"result\": read_file(folder_name, action[\"args\"].get(\"file_name\", \"\"))}\n",
        "        elif action[\"tool_name\"] == \"error\":\n",
        "            result = {\"error\": action[\"args\"][\"message\"]}\n",
        "        elif action[\"tool_name\"] == \"terminate\":\n",
        "            print(\"\\n✅ Agent Terminated:\", action[\"args\"][\"message\"])\n",
        "            break\n",
        "        else:\n",
        "            result = {\"error\": f\"Unknown action: {action['tool_name']}\"}\n",
        "\n",
        "        print(f\"\\n📄 Action Result:\\n{result}\")\n",
        "\n",
        "        memory.extend([\n",
        "            {\"role\": \"assistant\", \"content\": response},\n",
        "            {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "        ])\n",
        "\n",
        "        if action[\"tool_name\"] == \"terminate\":\n",
        "            break\n",
        "\n",
        "        iterations += 1\n",
        "\n",
        "    print(\"\\n💾 Agent Finished Loop.\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LDrRcAHgc7Cl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Input - 1 : Read the file notes.txt"
      ],
      "metadata": {
        "id": "jrlR1dXviqm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Main Entry Point\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Simple AI Agent (Folder-Specific Version) ===\")\n",
        "    folder_name = input(\"Enter folder name in the current directory: \").strip()\n",
        "    user_query = input(\"Ask the agent something (e.g., 'What files are here?' or 'Read the file notes.txt'): \")\n",
        "    run_agent(folder_name, user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPj15mT4ef__",
        "outputId": "6e5794e4-30b9-416c-9eba-656c7f0aa9cb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Simple AI Agent (Folder-Specific Version) ===\n",
            "Enter folder name in the current directory: Sample_Data_2\n",
            "Ask the agent something (e.g., 'What files are here?' or 'Read the file notes.txt'): Read the file notes.txt\n",
            "\n",
            "Agent thinking...\n",
            "\n",
            "🧠 Agent Response:\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"list_files\",\n",
            "    \"args\": {\n",
            "        \"folder_name\": \"Sample_Data_2\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "🧩 Parsed Action: {'tool_name': 'list_files', 'args': {'folder_name': 'Sample_Data_2'}}\n",
            "\n",
            "📄 Action Result:\n",
            "{'result': ['todo.md', 'readme.txt', 'notes.txt', 'data.json', '.ipynb_checkpoints']}\n",
            "\n",
            "Agent thinking...\n",
            "\n",
            "🧠 Agent Response:\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"read_file\",\n",
            "    \"args\": {\n",
            "        \"folder_name\": \"Sample_Data_2\",\n",
            "        \"file_name\": \"notes.txt\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "🧩 Parsed Action: {'tool_name': 'read_file', 'args': {'folder_name': 'Sample_Data_2', 'file_name': 'notes.txt'}}\n",
            "\n",
            "📄 Action Result:\n",
            "{'result': 'Meeting notes for project X:\\n- Review progress on backend integration\\n- Test API responses\\n- Update documentation\\n'}\n",
            "\n",
            "Agent thinking...\n",
            "\n",
            "🧠 Agent Response:\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"terminate\",\n",
            "    \"args\": {\n",
            "        \"message\": \"File notes.txt has been read. Contents: Meeting notes for project X:\\n- Review progress on backend integration\\n- Test API responses\\n- Update documentation\\n\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "🧩 Parsed Action: {'tool_name': 'terminate', 'args': {'message': 'File notes.txt has been read. Contents: Meeting notes for project X:\\n- Review progress on backend integration\\n- Test API responses\\n- Update documentation\\n'}}\n",
            "\n",
            "✅ Agent Terminated: File notes.txt has been read. Contents: Meeting notes for project X:\n",
            "- Review progress on backend integration\n",
            "- Test API responses\n",
            "- Update documentation\n",
            "\n",
            "\n",
            "💾 Agent Finished Loop.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Input - 2 : Read the file todo.md and also list the tasks that are not completed."
      ],
      "metadata": {
        "id": "57j5NHMoiv62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Main Entry Point\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Simple AI Agent (Folder-Specific Version) ===\")\n",
        "    folder_name = input(\"Enter folder name in the current directory: \").strip()\n",
        "    user_query = input(\"Ask the agent something (e.g., 'What files are here?' or 'Read the file notes.txt'): \")\n",
        "    run_agent(folder_name, user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuTEUlriiTSQ",
        "outputId": "c3422743-2d69-4a34-b0b9-509e498e251b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Simple AI Agent (Folder-Specific Version) ===\n",
            "Enter folder name in the current directory: Sample_Data_2\n",
            "Ask the agent something (e.g., 'What files are here?' or 'Read the file notes.txt'): Read the file todo.md and also list the tasks that are not completed.\n",
            "\n",
            "Agent thinking...\n",
            "\n",
            "🧠 Agent Response:\n",
            "To read the file and list tasks that are not completed, first, it's necessary to list all files to confirm the existence of \"todo.md\", and then read its content.\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"list_files\",\n",
            "    \"args\": {\n",
            "        \"folder_name\": \"Sample_Data_2\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "🧩 Parsed Action: {'tool_name': 'list_files', 'args': {'folder_name': 'Sample_Data_2'}}\n",
            "\n",
            "📄 Action Result:\n",
            "{'result': ['todo.md', 'readme.txt', 'notes.txt', 'data.json', '.ipynb_checkpoints']}\n",
            "\n",
            "Agent thinking...\n",
            "\n",
            "🧠 Agent Response:\n",
            "The file \"todo.md\" exists. Now, we can read its content.\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"read_file\",\n",
            "    \"args\": {\n",
            "        \"folder_name\": \"Sample_Data_2\",\n",
            "        \"file_name\": \"todo.md\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "🧩 Parsed Action: {'tool_name': 'read_file', 'args': {'folder_name': 'Sample_Data_2', 'file_name': 'todo.md'}}\n",
            "\n",
            "📄 Action Result:\n",
            "{'result': '# To-Do List\\n\\n- [x] Setup agent framework\\n- [ ] Implement persistent memory\\n- [ ] Add API tool support\\n'}\n",
            "\n",
            "Agent thinking...\n",
            "\n",
            "🧠 Agent Response:\n",
            "The content of \"todo.md\" has been read. The tasks that are not completed are:\n",
            "\n",
            "- Implement persistent memory\n",
            "- Add API tool support\n",
            "\n",
            "These tasks are listed as not completed because they do not have an 'x' in their checkboxes.\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"terminate\",\n",
            "    \"args\": {\n",
            "        \"message\": \"Tasks that are not completed: Implement persistent memory, Add API tool support\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "🧩 Parsed Action: {'tool_name': 'terminate', 'args': {'message': 'Tasks that are not completed: Implement persistent memory, Add API tool support'}}\n",
            "\n",
            "✅ Agent Terminated: Tasks that are not completed: Implement persistent memory, Add API tool support\n",
            "\n",
            "💾 Agent Finished Loop.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7oyLfD5iX1m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
