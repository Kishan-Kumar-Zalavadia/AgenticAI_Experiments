{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRaIBDz0MDcN5nkaGJaLk4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kishan-Kumar-Zalavadia/AgenticAI_Experiments/blob/main/1_Quasi_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Quasi-Agent"
      ],
      "metadata": {
        "id": "Et6A_UXQSNz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For practice, we are going to write a quasi-agent that can write Python functions based on user requirements. It isn’t quite a real agent, it can’t react and adapt, but it can do something useful for us.\n",
        "\n",
        "The quasi-agent will ask the user what they want code for, write the code for the function, add documentation, and finally include test cases using the unittest framework. This exercise will help you understand how to maintain context across multiple prompts and manage the information flow between the user and the LLM. It will also help you understand the pain of trying to parse and handle the output of an LLM that is not always consistent.\n",
        "\n"
      ],
      "metadata": {
        "id": "IKjgoagaSRlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice Exercise**\n",
        "\n",
        "This exercise will allow you to practice programmatically sending prompts to an LLM and managing memory.\n",
        "\n",
        "For this exercise, you should write a program that uses sequential prompts to generate any Python function based on user input. The program should:\n",
        "\n",
        "1. First Prompt:\n",
        "\n",
        "    - Ask the user what function they want to create\n",
        "    - Ask the LLM to write a basic Python function based on the user’s description\n",
        "    - Store the response for use in subsequent prompts\n",
        "    - Parse the response to separate the code from the commentary by the LLM\n",
        "\n",
        "2. Second Prompt:\n",
        "\n",
        "    - Pass the code generated from the first prompt\n",
        "    - Ask the LLM to add comprehensive documentation including:\n",
        "      - Function description\n",
        "      - Parameter descriptions\n",
        "      - Return value description\n",
        "      - Example usage\n",
        "      - Edge cases\n",
        "\n",
        "3. Third Prompt:\n",
        "\n",
        "    - Pass the documented code generated from the second prompt\n",
        "    - Ask the LLM to add test cases using Python’s unittest framework\n",
        "    - Tests should cover:\n",
        "      - Basic functionality\n",
        "      - Edge cases\n",
        "      - Error cases\n",
        "      - Various input scenarios\n",
        "\n",
        "Requirements:\n",
        "\n",
        "  - Use the LiteLLM library\n",
        "  - Maintain conversation context between prompts\n",
        "  - Print each step of the development process\n",
        "  - Save the final version to a Python file\n",
        "\n",
        "If you want to practice further, try using the system message to force the LLM to always output code that has a specific style or uses particular libraries."
      ],
      "metadata": {
        "id": "fYH8ETcpSUt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwRGs0CLSf3b",
        "outputId": "501e4488-3f58-4e2a-a2e6-835caaac5882"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting litellm',\n",
              " '  Downloading litellm-1.78.3-py3-none-any.whl.metadata (42 kB)',\n",
              " '\\x1b[?25l     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/42.9 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━\\x1b[0m \\x1b[32m41.0/42.9 kB\\x1b[0m \\x1b[31m130.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m42.9/42.9 kB\\x1b[0m \\x1b[31m917.8 kB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hRequirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm) (3.13.0)',\n",
              " 'Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm) (8.3.0)',\n",
              " 'Collecting fastuuid>=0.13.0 (from litellm)',\n",
              " '  Downloading fastuuid-0.13.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)',\n",
              " 'Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (0.28.1)',\n",
              " 'Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (8.7.0)',\n",
              " 'Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm) (3.1.6)',\n",
              " 'Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (4.25.1)',\n",
              " 'Requirement already satisfied: openai>=1.99.5 in /usr/local/lib/python3.12/dist-packages (from litellm) (1.109.1)',\n",
              " 'Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (2.11.10)',\n",
              " 'Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (1.1.1)',\n",
              " 'Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (0.12.0)',\n",
              " 'Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm) (0.22.1)',\n",
              " 'Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (2.6.1)',\n",
              " 'Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.4.0)',\n",
              " 'Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (25.4.0)',\n",
              " 'Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.8.0)',\n",
              " 'Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (6.7.0)',\n",
              " 'Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (0.4.1)',\n",
              " 'Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.22.0)',\n",
              " 'Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (4.11.0)',\n",
              " 'Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (2025.10.5)',\n",
              " 'Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (1.0.9)',\n",
              " 'Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (3.11)',\n",
              " 'Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)',\n",
              " 'Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)',\n",
              " 'Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.3)',\n",
              " 'Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2025.9.1)',\n",
              " 'Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.37.0)',\n",
              " 'Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.27.1)',\n",
              " 'Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm) (1.9.0)',\n",
              " 'Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm) (0.11.0)',\n",
              " 'Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm) (1.3.1)',\n",
              " 'Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm) (4.67.1)',\n",
              " 'Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm) (4.15.0)',\n",
              " 'Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.7.0)',\n",
              " 'Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (2.33.2)',\n",
              " 'Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.4.2)',\n",
              " 'Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)',\n",
              " 'Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.7.0->litellm) (2.32.4)',\n",
              " 'Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm) (0.35.3)',\n",
              " 'Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (3.20.0)',\n",
              " 'Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (2025.3.0)',\n",
              " 'Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (25.0)',\n",
              " 'Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (6.0.3)',\n",
              " 'Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.1.10)',\n",
              " 'Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.4)',\n",
              " 'Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.5.0)',\n",
              " 'Downloading litellm-1.78.3-py3-none-any.whl (9.8 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/9.8 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m1.1/9.8 MB\\x1b[0m \\x1b[31m32.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m5.7/9.8 MB\\x1b[0m \\x1b[31m83.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m9.8/9.8 MB\\x1b[0m \\x1b[31m107.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m9.8/9.8 MB\\x1b[0m \\x1b[31m74.9 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading fastuuid-0.13.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/272.3 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m272.3/272.3 kB\\x1b[0m \\x1b[31m22.7 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hInstalling collected packages: fastuuid, litellm',\n",
              " 'Successfully installed fastuuid-0.13.5 litellm-1.78.3']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "2Hc3AvSvSjZb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppt01XYtSGnQ",
        "outputId": "ba66d990-cc32-46ea-ace5-cf51413ae686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "What kind of function would you like to create?\n",
            "Example: 'A function that calculates the factorial of a number'\n",
            "Your description: A function to find sum of n natural numbers\n",
            "\n",
            "=== Initial Function ===\n",
            "def sum_of_natural_numbers(n):\n",
            "    \"\"\"\n",
            "    This function calculates the sum of the first n natural numbers.\n",
            "    \n",
            "    Parameters:\n",
            "    n (int): The number of natural numbers to sum up.\n",
            "    \n",
            "    Returns:\n",
            "    int: The sum of the first n natural numbers.\n",
            "    \"\"\"\n",
            "    if not isinstance(n, int) or n <= 0:\n",
            "        raise ValueError(\"Input should be a positive integer.\")\n",
            "    \n",
            "    # Using the formula for the sum of an arithmetic series: n * (n + 1) / 2\n",
            "    return n * (n + 1) // 2\n",
            "\n",
            "# Example usage:\n",
            "print(sum_of_natural_numbers(10))  # Output: 55\n",
            "\n",
            "=== Documented Function ===\n",
            "def sum_of_natural_numbers(n):\n",
            "    \"\"\"\n",
            "    This function calculates the sum of the first n natural numbers.\n",
            "\n",
            "    The sum of the first n natural numbers can be calculated using the formula: \n",
            "    1 + 2 + 3 + ... + n = n * (n + 1) / 2. This function implements this formula.\n",
            "\n",
            "    Parameters:\n",
            "    n (int): The number of natural numbers to sum up. This should be a positive integer.\n",
            "\n",
            "    Returns:\n",
            "    int: The sum of the first n natural numbers.\n",
            "\n",
            "    Examples:\n",
            "    >>> sum_of_natural_numbers(1)\n",
            "    1\n",
            "    >>> sum_of_natural_numbers(2)\n",
            "    3\n",
            "    >>> sum_of_natural_numbers(3)\n",
            "    6\n",
            "    >>> sum_of_natural_numbers(10)\n",
            "    55\n",
            "\n",
            "    Edge Cases:\n",
            "    - If n is not an integer, a ValueError is raised.\n",
            "    - If n is not a positive integer, a ValueError is raised.\n",
            "    - If n is a very large number, the function may return an incorrect result due to integer overflow.\n",
            "\n",
            "    Raises:\n",
            "    ValueError: If n is not a positive integer.\n",
            "\n",
            "    Notes:\n",
            "    - This function uses integer division (//) to ensure the result is an integer.\n",
            "    - This function does not handle non-integer inputs or non-positive integers.\n",
            "\n",
            "    :param n: The number of natural numbers to sum up.\n",
            "    :return: The sum of the first n natural numbers.\n",
            "    :rtype: int\n",
            "    \"\"\"\n",
            "    if not isinstance(n, int) or n <= 0:\n",
            "        raise ValueError(\"Input should be a positive integer.\")\n",
            "    \n",
            "    # Using the formula for the sum of an arithmetic series: n * (n + 1) / 2\n",
            "    return n * (n + 1) // 2\n",
            "\n",
            "# Example usage:\n",
            "print(sum_of_natural_numbers(10))  # Output: 55\n",
            "\n",
            "=== Test Cases ===\n",
            "import unittest\n",
            "\n",
            "def sum_of_natural_numbers(n):\n",
            "    \"\"\"\n",
            "    This function calculates the sum of the first n natural numbers.\n",
            "\n",
            "    The sum of the first n natural numbers can be calculated using the formula: \n",
            "    1 + 2 + 3 + ... + n = n * (n + 1) / 2. This function implements this formula.\n",
            "\n",
            "    Parameters:\n",
            "    n (int): The number of natural numbers to sum up. This should be a positive integer.\n",
            "\n",
            "    Returns:\n",
            "    int: The sum of the first n natural numbers.\n",
            "\n",
            "    Examples:\n",
            "    >>> sum_of_natural_numbers(1)\n",
            "    1\n",
            "    >>> sum_of_natural_numbers(2)\n",
            "    3\n",
            "    >>> sum_of_natural_numbers(3)\n",
            "    6\n",
            "    >>> sum_of_natural_numbers(10)\n",
            "    55\n",
            "\n",
            "    Edge Cases:\n",
            "    - If n is not an integer, a ValueError is raised.\n",
            "    - If n is not a positive integer, a ValueError is raised.\n",
            "    - If n is a very large number, the function may return an incorrect result due to integer overflow.\n",
            "\n",
            "    Raises:\n",
            "    ValueError: If n is not a positive integer.\n",
            "\n",
            "    Notes:\n",
            "    - This function uses integer division (//) to ensure the result is an integer.\n",
            "    - This function does not handle non-integer inputs or non-positive integers.\n",
            "\n",
            "    :param n: The number of natural numbers to sum up.\n",
            "    :return: The sum of the first n natural numbers.\n",
            "    :rtype: int\n",
            "    \"\"\"\n",
            "    if not isinstance(n, int) or n <= 0:\n",
            "        raise ValueError(\"Input should be a positive integer.\")\n",
            "    \n",
            "    # Using the formula for the sum of an arithmetic series: n * (n + 1) / 2\n",
            "    return n * (n + 1) // 2\n",
            "\n",
            "class TestSumOfNaturalNumbers(unittest.TestCase):\n",
            "\n",
            "    # Basic functionality tests\n",
            "    def test_sum_of_first_natural_number(self):\n",
            "        self.assertEqual(sum_of_natural_numbers(1), 1)\n",
            "\n",
            "    def test_sum_of_first_few_natural_numbers(self):\n",
            "        self.assertEqual(sum_of_natural_numbers(2), 3)\n",
            "        self.assertEqual(sum_of_natural_numbers(3), 6)\n",
            "        self.assertEqual(sum_of_natural_numbers(10), 55)\n",
            "\n",
            "    # Edge case tests\n",
            "    def test_zero(self):\n",
            "        with self.assertRaises(ValueError):\n",
            "            sum_of_natural_numbers(0)\n",
            "\n",
            "    def test_negative_number(self):\n",
            "        with self.assertRaises(ValueError):\n",
            "            sum_of_natural_numbers(-1)\n",
            "        with self.assertRaises(ValueError):\n",
            "            sum_of_natural_numbers(-10)\n",
            "\n",
            "    # Error case tests\n",
            "    def test_non_integer_input(self):\n",
            "        with self.assertRaises(ValueError):\n",
            "            sum_of_natural_numbers(3.5)\n",
            "        with self.assertRaises(ValueError):\n",
            "            sum_of_natural_numbers(\"10\")\n",
            "\n",
            "    # Various input scenario tests\n",
            "    def test_large_input(self):\n",
            "        self.assertEqual(sum_of_natural_numbers(100), 5050)\n",
            "\n",
            "    def test_single_digit_input(self):\n",
            "        self.assertEqual(sum_of_natural_numbers(5), 15)\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    unittest.main()\n",
            "\n",
            "Final code has been saved to a_function_to_find_sum_of_n_na.py\n"
          ]
        }
      ],
      "source": [
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"groq/llama-3.3-70b-versatile\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "def extract_code_block(response: str) -> str:\n",
        "    \"\"\"Extract code block from response\"\"\"\n",
        "    if '```' not in response:\n",
        "        return response\n",
        "\n",
        "    code_block = response.split('```')[1].strip()\n",
        "\n",
        "    # Remove \"python\" prefix if present\n",
        "    if code_block.startswith(\"python\"):\n",
        "        code_block = code_block[6:].strip()\n",
        "\n",
        "    return code_block\n",
        "\n",
        "\n",
        "def develop_custom_function():\n",
        "    \"\"\"Main function to interactively develop and enhance a Python function\"\"\"\n",
        "\n",
        "    # Step 1: Get user input\n",
        "    print(\"\\nWhat kind of function would you like to create?\")\n",
        "    print(\"Example: 'A function that calculates the factorial of a number'\")\n",
        "    function_description = input(\"Your description: \").strip()\n",
        "\n",
        "    # Initialize conversation\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a Python expert helping to develop a function.\"}\n",
        "    ]\n",
        "\n",
        "    # Step 2: Generate initial function\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"Write a Python function that {function_description}. Output the function in a ```python code block```.\"\n",
        "    })\n",
        "\n",
        "    initial_function = generate_response(messages)\n",
        "    initial_function = extract_code_block(initial_function)\n",
        "\n",
        "    print(\"\\n=== Initial Function ===\")\n",
        "    print(initial_function)\n",
        "\n",
        "    # Add assistant's last code-only reply to maintain context\n",
        "    messages.append({\"role\": \"assistant\", \"content\": f\"```python\\n{initial_function}\\n```\"})\n",
        "\n",
        "    # Step 3: Add documentation\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"Add comprehensive documentation to this function, including description, parameters, \"\n",
        "            \"return value, examples, and edge cases. Output the function in a ```python code block```.\"\n",
        "        )\n",
        "    })\n",
        "\n",
        "    documented_function = generate_response(messages)\n",
        "    documented_function = extract_code_block(documented_function)\n",
        "\n",
        "    print(\"\\n=== Documented Function ===\")\n",
        "    print(documented_function)\n",
        "\n",
        "    messages.append({\"role\": \"assistant\", \"content\": f\"```python\\n{documented_function}\\n```\"})\n",
        "\n",
        "    # Step 4: Add test cases\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"Add unittest test cases for this function, including tests for basic functionality, \"\n",
        "            \"edge cases, error cases, and various input scenarios. Output the code in a ```python code block```.\"\n",
        "        )\n",
        "    })\n",
        "\n",
        "    test_cases = generate_response(messages)\n",
        "    test_cases = extract_code_block(test_cases)\n",
        "\n",
        "    print(\"\\n=== Test Cases ===\")\n",
        "    print(test_cases)\n",
        "\n",
        "    # Step 5: Save to file\n",
        "    filename = function_description.lower()\n",
        "    filename = ''.join(c for c in filename if c.isalnum() or c.isspace())\n",
        "    filename = filename.replace(' ', '_')[:30] + '.py'\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(documented_function + '\\n\\n' + test_cases)\n",
        "\n",
        "    print(f\"\\nFinal code has been saved to {filename}\")\n",
        "    return documented_function, test_cases, filename\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    function_code, tests, filename = develop_custom_function()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding the Architecture\n",
        "\n",
        "Our quasi-agent works through three key steps:\n",
        "\n",
        "1. Initial code generation\n",
        "2. Documentation enhancement\n",
        "3. Test case creation\n",
        "\n",
        "The magic happens in how we maintain context between these steps, ensuring each builds on the previous results."
      ],
      "metadata": {
        "id": "MC67griJTNWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Core Components\n",
        "Let’s break down the key pieces:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"groq/llama-3.3-70b-versatile\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "```\n",
        "\n",
        "This function handles our LLM interactions using ChatML format. Each message includes a role (“system”, “user”, or “assistant”) and content.\n",
        "\n",
        "```\n",
        "def extract_code_block(response: str) -> str:\n",
        "    \"\"\"Extract code block from response\"\"\"\n",
        "    if not '```' in response:\n",
        "        return response\n",
        "\n",
        "    code_block = response.split('```')[1].strip()\n",
        "    if code_block.startswith(\"python\"):\n",
        "        code_block = code_block[6:]\n",
        "\n",
        "    return code_block\n",
        "```\n",
        "\n",
        "The LLM often includes commentary with its code. This function extracts just the code block, making it easier to build upon in subsequent prompts."
      ],
      "metadata": {
        "id": "xEYrFg5LTbc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Development Process\n",
        "\n",
        "The main function, develop_custom_function(), orchestrates three phases of development:\n",
        "\n",
        "## Phase 1: Initial Code Generation\n",
        "```\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a Python expert helping to develop a function.\"}\n",
        "]\n",
        "\n",
        "messages.append({\n",
        "    \"role\": \"user\",\n",
        "    \"content\": f\"Write a Python function that {function_description}. Output the function in a ```python code block```.\"\n",
        "})\n",
        "```\n",
        "\n",
        "We start with a system message establishing the LLM’s role, then request initial code based on the user’s description.\n",
        "\n",
        "# Phase 2: Documentation Enhancement\n",
        "\n",
        "```\n",
        "messages.append({\n",
        "    \"role\": \"assistant\",\n",
        "    \"content\": \"\\`\\`\\`python\\n\\n\"+initial_function+\"\\n\\n\\`\\`\\`\"\n",
        "})\n",
        "\n",
        "messages.append({\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"Add comprehensive documentation to this function...\"\n",
        "})\n",
        "```\n",
        "\n",
        "Notice how we feed back the code but strip any commentary. This keeps the LLM focused on just the code structure.\n",
        "\n",
        "\n",
        "# Phase 3: Test Case Generation\n",
        "```\n",
        "messages.append({\n",
        "    \"role\": \"assistant\",\n",
        "    \"content\": \"\\`\\`\\`python\\n\\n\"+documented_function+\"\\n\\n\\`\\`\\`\"\n",
        "})\n",
        "\n",
        "messages.append({\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"Add unittest test cases for this function...\"\n",
        "})\n",
        "```\n",
        "Again, we maintain clean context by showing only the documented code.\n",
        "\n"
      ],
      "metadata": {
        "id": "5xeuNqHaUD-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory Management Through Message History\n",
        "\n",
        "The key insight is how we manage “memory” through the messages list. Each step builds on previous responses, but we carefully control what the LLM sees:\n",
        "\n",
        "1. We only show the code, not the commentary\n",
        "2. Each message provides specific instruction for the next enhancement\n",
        "3. The context builds progressively through the message history\n",
        "For\n",
        " example, when adding documentation, the LLM sees:\n",
        "\n",
        "- It’s a Python expert (system message)\n",
        "- The original code (previous response)\n",
        "- The request for documentation (current task)\n",
        "This focused context helps ensure consistent, high-quality output.\n"
      ],
      "metadata": {
        "id": "3s_4_ve_UZKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usage Example\n",
        "Here’s how it works in practice:\n",
        "\n",
        "```\n",
        ">>> function_code, tests, filename = develop_custom_function()\n",
        "What kind of function would you like to create?\n",
        "Example: 'A function that calculates the factorial of a number'\n",
        "Your description: Calculate fibonacci sequence up to n\n",
        "\n",
        "=== Initial Function ===\n",
        "def fibonacci(n):\n",
        "    if n <= 0:\n",
        "        return []\n",
        "    elif n == 1:\n",
        "        return [0]\n",
        "    sequence = [0, 1]\n",
        "    while len(sequence) < n:\n",
        "        sequence.append(sequence[-1] + sequence[-2])\n",
        "    return sequence\n",
        "\n",
        "=== Documented Function ===\n",
        "[... function with added documentation ...]\n",
        "\n",
        "=== Test Cases ===\n",
        "[... unittest test cases ...]\n",
        "```\n",
        "\n",
        "Final code has been saved to calculate_fibonacci_sequence_up.py"
      ],
      "metadata": {
        "id": "nedywdlLU_2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning from This Design\n",
        "This quasi-agent teaches us several important lessons about building LLM-powered systems:\n",
        "\n",
        "1. **Prompt Chaining**: Breaking complex tasks into sequential steps makes them more manageable.\n",
        "\n",
        "2. **Context Management**: Carefully controlling what the LLM sees helps maintain focus and consistency.\n",
        "\n",
        "3. **Output Processing**: Having robust ways to extract and clean LLM output is crucial.\n",
        "\n",
        "4. **Progressive Enhancement**: Building features iteratively (code → docs → tests) creates better results than trying to do everything at once.\n",
        "\n",
        "These principles apply even when building more complex, fully agentic systems.\n",
        "\n"
      ],
      "metadata": {
        "id": "N0pbwLouUyuC"
      }
    }
  ]
}