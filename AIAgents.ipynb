{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIT120ipetZfd1F6JFLkjF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kishan-Kumar-Zalavadia/AgenticAI_Experiments/blob/main/AIAgents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCjVaLHXoMje",
        "outputId": "68442e90-c9cb-4e93-85d2-2809d2512b11"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: litellm in /usr/local/lib/python3.12/dist-packages (1.78.2)',\n",
              " 'Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm) (3.13.0)',\n",
              " 'Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm) (8.3.0)',\n",
              " 'Requirement already satisfied: fastuuid>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (0.13.5)',\n",
              " 'Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (0.28.1)',\n",
              " 'Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (8.7.0)',\n",
              " 'Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm) (3.1.6)',\n",
              " 'Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (4.25.1)',\n",
              " 'Requirement already satisfied: openai>=1.99.5 in /usr/local/lib/python3.12/dist-packages (from litellm) (1.109.1)',\n",
              " 'Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (2.11.10)',\n",
              " 'Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (1.1.1)',\n",
              " 'Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm) (0.12.0)',\n",
              " 'Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm) (0.22.1)',\n",
              " 'Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (2.6.1)',\n",
              " 'Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.4.0)',\n",
              " 'Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (25.4.0)',\n",
              " 'Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.8.0)',\n",
              " 'Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (6.7.0)',\n",
              " 'Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (0.3.2)',\n",
              " 'Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm) (1.22.0)',\n",
              " 'Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (4.11.0)',\n",
              " 'Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (2025.10.5)',\n",
              " 'Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (1.0.9)',\n",
              " 'Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm) (3.10)',\n",
              " 'Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)',\n",
              " 'Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)',\n",
              " 'Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.3)',\n",
              " 'Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2025.9.1)',\n",
              " 'Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.36.2)',\n",
              " 'Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.27.1)',\n",
              " 'Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm) (1.9.0)',\n",
              " 'Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm) (0.11.0)',\n",
              " 'Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm) (1.3.1)',\n",
              " 'Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm) (4.67.1)',\n",
              " 'Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.5->litellm) (4.15.0)',\n",
              " 'Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.7.0)',\n",
              " 'Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (2.33.2)',\n",
              " 'Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.4.2)',\n",
              " 'Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)',\n",
              " 'Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.7.0->litellm) (2.32.4)',\n",
              " 'Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm) (0.35.3)',\n",
              " 'Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (3.20.0)',\n",
              " 'Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (2025.3.0)',\n",
              " 'Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (25.0)',\n",
              " 'Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (6.0.3)',\n",
              " 'Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.1.10)',\n",
              " 'Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.3)',\n",
              " 'Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.5.0)']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "Lmg1KIvewIEv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Programmatic Prompting for Agents"
      ],
      "metadata": {
        "id": "6S7pgJ_3v3xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion\n",
        "from google.colab import userdata\n",
        "\n",
        "response = completion(\n",
        "    model=\"groq/llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert software engineer.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Write a function to swap keys and values in a dictionary.\"}\n",
        "    ],\n",
        "    max_tokens=128\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRqp1zpZn96_",
        "outputId": "8beccec7-10f9-4045-9ecd-86cdc83d84fc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Swapping Keys and Values in a Dictionary\n",
            "\n",
            "In Python, dictionaries are inherently one-way mappings, meaning each key corresponds to a unique value. However, we can swap keys and values by creating a new dictionary. This approach requires that the original dictionary's values are unique, as dictionaries cannot have duplicate keys.\n",
            "\n",
            "#### Code\n",
            "\n",
            "```python\n",
            "def swap_keys_values(dictionary):\n",
            "    \"\"\"\n",
            "    Swap keys and values in a dictionary.\n",
            "\n",
            "    Args:\n",
            "    dictionary (dict): The input dictionary.\n",
            "\n",
            "    Returns:\n",
            "    dict: A new dictionary with keys and values swapped.\n",
            "\n",
            "    Raises:\n",
            "    ValueError: If the dictionary's values are not unique.\n",
            "   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example-2"
      ],
      "metadata": {
        "id": "OFvuK6kVwTrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = completion(\n",
        "    model=\"groq/llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert cook.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Give me steps to make chicken curry.\"}\n",
        "    ],\n",
        "    max_tokens=1000\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_DWPhhqsFM7",
        "outputId": "ac7ddb1b-21a9-494f-89b7-eecaa05eaa4d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a simple and delicious recipe for chicken curry that serves 4-6 people:\n",
            "\n",
            "**Ingredients:**\n",
            "\n",
            "* 1 1/2 pounds boneless, skinless chicken breast or thighs, cut into 1-inch pieces\n",
            "* 2 medium onions, diced\n",
            "* 2 cloves of garlic, minced\n",
            "* 1 tablespoon grated fresh ginger\n",
            "* 1 tablespoon curry powder\n",
            "* 1 teaspoon ground cumin\n",
            "* 1/2 teaspoon turmeric powder\n",
            "* 1/2 teaspoon cayenne pepper (optional)\n",
            "* 1 can (14 oz) diced tomatoes\n",
            "* 1 cup chicken broth\n",
            "* 1/2 cup coconut milk (optional)\n",
            "* Salt and pepper, to taste\n",
            "* Fresh cilantro, for garnish\n",
            "\n",
            "**Instructions:**\n",
            "\n",
            "1. **Heat oil in a pan**: Heat 2 tablespoons of oil in a large pan or Dutch oven over medium heat.\n",
            "2. **Sauté onions**: Add the diced onions and cook until they are translucent and starting to brown, about 5-7 minutes.\n",
            "3. **Add garlic and ginger**: Add the minced garlic and grated ginger and cook for 1 minute, stirring constantly.\n",
            "4. **Add spices**: Add the curry powder, cumin, turmeric, and cayenne pepper (if using) and cook for 1-2 minutes, stirring constantly, until the spices are fragrant.\n",
            "5. **Add chicken**: Add the chicken pieces and cook until they are browned on all sides and cooked through, about 5-7 minutes.\n",
            "6. **Add diced tomatoes and chicken broth**: Add the diced tomatoes and chicken broth, and stir to combine. Bring the mixture to a simmer.\n",
            "7. **Reduce heat and let it cook**: Reduce the heat to low and let the curry simmer, covered, for 20-25 minutes, or until the chicken is cooked through and the sauce has thickened.\n",
            "8. **Add coconut milk (optional)**: If using coconut milk, stir it in during the last 5 minutes of cooking.\n",
            "9. **Season with salt and pepper**: Season the curry with salt and pepper to taste.\n",
            "10. **Garnish and serve**: Garnish with fresh cilantro and serve over rice or with naan or roti.\n",
            "\n",
            "**Tips and Variations:**\n",
            "\n",
            "* Use bone-in chicken pieces for a more flavorful curry.\n",
            "* Add other spices, such as cinnamon, cardamom, or cloves, to the curry for added depth of flavor.\n",
            "* Use Greek yogurt or sour cream instead of coconut milk for a creamier curry.\n",
            "* Add potatoes, carrots, or bell peppers to the curry for added flavor and nutrients.\n",
            "* Make the curry ahead of time and refrigerate or freeze it for later use.\n",
            "\n",
            "Enjoy your delicious homemade chicken curry!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s break down the key components:\n",
        "\n",
        "1. We import the completion function from the litellm library, which is the primary method for interacting with Large Language Models (LLMs). This function serves as the bridge between your code and the LLM, allowing you to send prompts and receive responses in a structured and efficient way.\n",
        "\n",
        "    How completion Works:\n",
        "\n",
        "    - Input: You provide a prompt, which is a list of messages that you want the model to process. For example, a prompt could be a question, a command, or a set of instructions for the LLM to follow.\n",
        "    - Output: The completion function returns the model’s response, typically in the form of generated text based on your prompt.\n",
        "\n",
        "2. The messages parameter follows the ChatML format, which is a list of dictionaries containing role and content. The role attribute indicates who is “speaking” in the conversation. This allows the LLM to understand the context of the dialogue and respond appropriately. The roles include:\n",
        "\n",
        "  - “system”: Provides the model with initial instructions, rules, or configuration for how it should behave throughout the session. This message is not part of the “conversation” but sets the ground rules or context (e.g., “You will respond in JSON.”).\n",
        "  - “user”: Represents input from the user. This is where you provide your prompts, questions, or instructions.\n",
        "  - “assistant”: Represents responses from the AI model. You can include this role to provide context for a conversation that has already started or to guide the model by showing sample responses. These messages are interpreted as what the “model” said in the passt.\n",
        "\n",
        "3. We specify the model using the provider/model format (e.g., “openai/gpt-4o”)\n",
        "\n",
        "4. The response contains the generated text in choices[0].message.content. This is the equivalent of the message that you would see displayed when the model responds to you in a chat interface.\n",
        "\n"
      ],
      "metadata": {
        "id": "ea5X7k0vvX1z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRyvTSE9vYwT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}