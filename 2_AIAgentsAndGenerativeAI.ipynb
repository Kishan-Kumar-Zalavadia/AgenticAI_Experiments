{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlgYSSwUD/t+eEgu+pdp64",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kishan-Kumar-Zalavadia/Agentic_AI_with_Python_And_Generative_AI/blob/main/2_AIAgentsAndGenerativeAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AI-Agent Tool Descriptions and Naming**\n",
        "\n",
        "## **Describing Tools to the Agent**\n",
        "\n",
        "When developing an agentic AI system, one of the most critical aspects is ensuring that the agent understands the tools it has access to. In our previous tutorial, we explored how an AI agent interacts with an environment. Now, we extend that discussion to focus on tool definition, particularly the importance of naming, parameters, and structured metadata.\n",
        "\n",
        "## **Example: Automating Documentation for Python Code**\n",
        "\n",
        "Imagine we are building an AI agent that scans through all Python files in a src/ directory and automatically generates corresponding documentation files in a docs/ directory. This agent will need to:\n",
        "\n",
        "- List Python files in the src/ directory.\n",
        "- Read the content of each Python file.\n",
        "- Write documentation files in the docs/ directory.\n",
        "\n",
        "Since file operations are straightforward for humans but ambiguous for an AI without context, we must clearly define these tools so the agent knows how to use them effectively.\n"
      ],
      "metadata": {
        "id": "7KQ6TFlTvYJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Defining a Tool with Structured Metadata**\n",
        "\n",
        "A basic tool definition in Python might look like this:\n",
        "\n",
        "```\n",
        "def list_python_files():\n",
        "    \"\"\"Returns a list of all Python files in the src/ directory.\"\"\"\n",
        "    return [f for f in os.listdir(\"src\") if f.endswith(\".py\")]\n",
        "```\n",
        "\n",
        "This provides a function that retrieves all Python files in the src/ directory, but for an AI system, we need a more structured way to describe it."
      ],
      "metadata": {
        "id": "1A8dT9msvtZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Using JSON Schema to Define Parameters**\n",
        "\n",
        "When developers design APIs, they use structured documentation to describe available functions, their inputs, and their outputs. JSON Schema is a well-known format for defining APIs, making it a natural choice for AI agents as well.\n",
        "\n",
        "For example, a tool that reads a file should specify that it expects a file_path parameter of type string. JSON Schema allows us to express this in a standardized way:\n",
        "\n",
        "```\n",
        "{\n",
        "  \"tool_name\": \"read_file\",\n",
        "  \"description\": \"Reads the content of a specified file.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"file_path\": { \"type\": \"string\" }\n",
        "    },\n",
        "    \"required\": [\"file_path\"]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "Similarly, a tool for writing documentation should define that it requires a file_name and content:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "  \"tool_name\": \"write_doc_file\",\n",
        "  \"description\": \"Writes a documentation file to the docs/ directory.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"file_name\": { \"type\": \"string\" },\n",
        "      \"content\": { \"type\": \"string\" }\n",
        "    },\n",
        "    \"required\": [\"file_name\", \"content\"]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "By providing a JSON Schema for each tool:\n",
        "\n",
        "1. The AI can Recognize the tool’s purpose.\n",
        "2. The AI / Environment interface can validate input parameters before execution.\n",
        "\n",
        "It may look strange that multiple parameters to a function are represented as an object. When we are getting the agent to output a tool / action selection, we are going to want it to output something like this:\n",
        "\n",
        "```\n",
        "{\n",
        "  \"tool_name\": \"read_file\",\n",
        "  \"args\": {\n",
        "    \"file_path\": \"src/file.py\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "The schema describes the overall dictionary that will be used to capture the “args” to the function, so it is described as an object.\n",
        "\n"
      ],
      "metadata": {
        "id": "X_yulBVuv2bc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install libraries"
      ],
      "metadata": {
        "id": "3kUFt15foY2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3ga4HsGoSWA"
      },
      "outputs": [],
      "source": [
        "!!pip install litellm\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent that Calls Python Functions\n",
        "\n",
        "Let's make an agent that can call Python functions.\n",
        "When you run the second block in the notebook, the agent will prompt you for what action to take. You can say something like \"tell me the files in the current directory\" and it will make the appropriate tool choice. Experiment with the agent to see what it can and cannot do."
      ],
      "metadata": {
        "id": "-MABBQjiwfyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
        "    \"\"\"Extract code block from response\"\"\"\n",
        "\n",
        "    if not '```' in response:\n",
        "        return response\n",
        "\n",
        "    code_block = response.split('```')[1].strip()\n",
        "\n",
        "    if code_block.startswith(block_type):\n",
        "        code_block = code_block[len(block_type):].strip()\n",
        "\n",
        "    return code_block\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get a response.\"\"\"\n",
        "    response = completion(\n",
        "        model=\"groq/llama-3.3-70b-versatile\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def parse_action(response: str) -> Dict:\n",
        "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
        "    try:\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "        response_json = json.loads(response)\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Define system instructions (Agent Rules)\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "Available tools:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"list_files\": {\n",
        "        \"description\": \"Lists all files in the current directory.\",\n",
        "        \"parameters\": {}\n",
        "    },\n",
        "    \"read_file\": {\n",
        "        \"description\": \"Reads the content of a file.\",\n",
        "        \"parameters\": {\n",
        "            \"file_name\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The name of the file to read.\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"terminate\": {\n",
        "        \"description\": \"Ends the agent loop and provides a summary of the task.\",\n",
        "        \"parameters\": {\n",
        "            \"message\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Summary message to return to the user.\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\n",
        "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
        "\n",
        "Important!!! Every response MUST have an action.\n",
        "You must ALWAYS respond in this format:\n",
        "\n",
        "<Stop and think step by step. Parameters map to args. Insert a rich description of your step by step thoughts here.>\n",
        "\n",
        "```action\n",
        "{\n",
        "    \"tool_name\": \"insert tool_name\",\n",
        "    \"args\": {...fill in any required arguments here...}\n",
        "}\n",
        "```\"\"\"\n",
        "}]\n",
        "\n",
        "# Initialize agent parameters\n",
        "iterations = 0\n",
        "max_iterations = 10\n",
        "\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "# The Agent Loop\n",
        "while iterations < max_iterations:\n",
        "    # 1. Construct prompt: Combine agent rules with memory\n",
        "    prompt = agent_rules + memory\n",
        "\n",
        "    # 2. Generate response from LLM\n",
        "    print(\"Agent thinking...\")\n",
        "    response = generate_response(prompt)\n",
        "    print(f\"Agent response: {response}\")\n",
        "\n",
        "    # 3. Parse response to determine action\n",
        "    action = parse_action(response)\n",
        "    result = \"Action executed\"\n",
        "\n",
        "    if action[\"tool_name\"] == \"list_files\":\n",
        "        result = {\"result\": list_files()}\n",
        "    elif action[\"tool_name\"] == \"read_file\":\n",
        "        result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
        "    elif action[\"tool_name\"] == \"error\":\n",
        "        result = {\"error\": action[\"args\"][\"message\"]}\n",
        "    elif action[\"tool_name\"] == \"terminate\":\n",
        "        print(action[\"args\"][\"message\"])\n",
        "        break\n",
        "    else:\n",
        "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
        "\n",
        "    print(f\"Action result: {result}\")\n",
        "\n",
        "    # 5. Update memory with response and results\n",
        "    memory.extend([\n",
        "        {\"role\": \"assistant\", \"content\": response},\n",
        "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "    ])\n",
        "\n",
        "    # 6. Check termination condition\n",
        "    if action[\"tool_name\"] == \"terminate\":\n",
        "        break\n",
        "\n",
        "    iterations += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3sk27nqwsvi",
        "outputId": "8ef8cca7-70f5-4aee-a6a3-08057d361b53"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? Tell me what is in the dir.\n",
            "Agent thinking...\n",
            "Agent response: To find out what is in the current directory, I need to list all the files. This will give me a clear understanding of the files available before I can proceed with any further actions. By listing the files, I can identify the types of documents or content available and provide a more accurate response to the user's inquiry.\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"list_files\",\n",
            "    \"args\": {}\n",
            "}\n",
            "```\n",
            "Action result: {'result': ['.config', 'Readme.txt', '.ipynb_checkpoints', 'sample_data']}\n",
            "Agent thinking...\n",
            "Agent response: The directory contains several files and directories, including \".config\", \"Readme.txt\", \".ipynb_checkpoints\", and \"sample_data\". Since the user initially asked about the contents of the directory, I should now read the \"Readme.txt\" file to provide more information about the directory's contents. The \"Readme.txt\" file often contains important information or descriptions about the directory and its files.\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"read_file\",\n",
            "    \"args\": {\n",
            "        \"file_name\": \"Readme.txt\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "Action result: {'result': 'This is a test file to see how Agentic AI performs.'}\n",
            "Agent thinking...\n",
            "Agent response: I have now read the contents of the \"Readme.txt\" file, which contains a test message to evaluate the performance of Agentic AI. Since I have completed the task of listing the files and reading the \"Readme.txt\" file, I can now terminate the conversation and provide a summary of the task. The summary will include the fact that the directory contains several files and directories, and the \"Readme.txt\" file contains a test message.\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"terminate\",\n",
            "    \"args\": {\n",
            "        \"message\": \"The directory contains .config, Readme.txt, .ipynb_checkpoints, and sample_data. The Readme.txt file contains a test message.\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "The directory contains .config, Readme.txt, .ipynb_checkpoints, and sample_data. The Readme.txt file contains a test message.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using LLM Function Calling for AI-Agent Interaction**\n",
        "\n",
        "# Step 3: Using LLM Function Calling for Structured Execution\n",
        "\n",
        "One of the most challenging aspects of integrating AI agents with tool execution is ensuring that the model consistently produces structured output that can be parsed correctly. Traditionally, developers would attempt to engineer prompts to make the model output well-formed JSON, but this approach is unreliable—models can introduce variations, omit required fields, or output unstructured text that breaks parsing logic.\n",
        "\n",
        "To solve this, most LLMs offer function calling APIs that guarantee structured execution. Instead of treating function execution as a free-form text generation task, function calling APIs allow us to explicitly define the tools available to the model using JSON Schema. The model then decides when and how to call these functions, ensuring structured and predictable responses.\n",
        "\n",
        "## How Function Calling Simplifies AI-Agent Interfaces\n",
        "\n",
        "When using function calling, the model returns either:\n",
        "\n",
        "1. A function call that includes the tool name and arguments as structured JSON.\n",
        "2. A standard text response if the model decides a function is unnecessary.\n",
        "\n",
        "This approach removes the need for manual prompt engineering to enforce structured output and allows the agent to focus on decision-making rather than syntax compliance.\n",
        "\n"
      ],
      "metadata": {
        "id": "A8TPanCWzkOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Executing Function Calls\n",
        "\n",
        "Below is a typical way to invoke function calling using OpenAI’s API:\n",
        "\n"
      ],
      "metadata": {
        "id": "yDWOYAZU0tUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "\n",
        "from litellm import completion\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "tool_functions = {\n",
        "    \"list_files\": list_files,\n",
        "    \"read_file\": read_file\n",
        "}\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Returns a list of files in the directory.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Our rules are simplified since we don't have to worry about getting a specific output format\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\"\"\"\n",
        "}]\n",
        "\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "messages = agent_rules + memory\n",
        "\n",
        "response = completion(\n",
        "    model=\"groq/llama-3.3-70b-versatile\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "# Extract the tool call from the response, note we don't have to parse now!\n",
        "tool = response.choices[0].message.tool_calls[0]\n",
        "tool_name = tool.function.name\n",
        "tool_args = json.loads(tool.function.arguments)\n",
        "result = tool_functions[tool_name](**tool_args)\n",
        "\n",
        "print(f\"Tool Name: {tool_name}\")\n",
        "print(f\"Tool Arguments: {tool_args}\")\n",
        "print(f\"Result: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYC2E5FJzmkE",
        "outputId": "836c443b-c40f-49b3-feba-0fb8f2be6886"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? Give me the list of files in the directory\n",
            "Tool Name: list_files\n",
            "Tool Arguments: {}\n",
            "Result: ['.config', 'Readme.txt', '.ipynb_checkpoints', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Breaking Down Function Calling Step by Step\n",
        "\n",
        "Let’s examine how function calling works in detail:\n",
        "\n",
        "## 1. Define the Tool Functions\n",
        "\n",
        "```\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "```\n",
        "First, we define the actual Python functions that will be executed. These contain the business logic for each tool and handle the actual operations the AI agent can perform."
      ],
      "metadata": {
        "id": "zDiK1KRg2ALx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create a Function Registry\n",
        "\n",
        "```\n",
        "tool_functions = {\n",
        "    \"list_files\": list_files,\n",
        "    \"read_file\": read_file\n",
        "}\n",
        "```\n",
        "\n",
        "We maintain a dictionary that maps function names to their corresponding Python implementations. This registry allows us to easily look up and execute the appropriate function when the model calls it.\n",
        "\n",
        "## 3. Define Tool Specifications Using JSON Schema\n",
        "```\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Returns a list of files in the directory.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "This is where we describe our tools to the model. Each tool specification includes:\n",
        "\n",
        "- A name that matches a key in our tool_functions dictionary\n",
        "- A description that helps the model understand when to use this tool\n",
        "- Parameters defined using JSON Schema, specifying the expected input format\n",
        "\n",
        "Note how the list_files function takes no parameters (empty “properties” object), while read_file requires a “file_name” string parameter. The model will use these specifications to generate properly structured calls.\n",
        "\n",
        "## 4. Set Up the Agent’s Instructions\n",
        "\n",
        "```\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\"\"\"\n",
        "}]\n",
        "```\n",
        "\n",
        "The system message provides guidance on how the agent should behave. With function calling, we don’t need to instruct the model on how to format its outputs - we only need to focus on the decision-making logic.\n",
        "\n",
        "The system message provides guidance on how the agent should behave. With function calling, we don’t need to instruct the model on how to format its outputs - we only need to focus on the decision-making logic.\n",
        "\n",
        "## 5. Prepare the Conversation Context\n",
        "\n",
        "```\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "messages = agent_rules + memory\n",
        "```\n",
        "\n",
        "We combine the system instructions with the user’s input to create the conversation context.\n",
        "\n",
        "## 6. Make the API Call with Function Definitions\n",
        "\n",
        "```\n",
        "response = completion(\n",
        "    model=\"openai/gpt-4o\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    max_tokens=1024\n",
        ")\n",
        "```\n",
        "\n",
        "The critical difference here is the inclusion of the tools parameter, which tells the model what functions it can call. This is what activates the function calling mechanism.\n",
        "\n",
        "## 7. Process the Structured Response\n",
        "```\n",
        "tool = response.choices[0].message.tool_calls[0]\n",
        "tool_name = tool.function.name\n",
        "tool_args = json.loads(tool.function.arguments)\n",
        "```\n",
        "\n",
        "When using function calling, the response comes back with a dedicated tool_calls array rather than free-text output. This ensures that:\n",
        "\n",
        "The function name is properly identified\n",
        "The arguments are correctly formatted as valid JSON\n",
        "We don’t need to parse or extract from unstructured text\n",
        "\n",
        "## 8. Execute the Function with the Provided Arguments\n",
        "\n",
        "```\n",
        "result = tool_functions[tool_name](**tool_args)\n",
        "```\n",
        "\n",
        "Finally, we look up the appropriate function in our registry and call it with the arguments the model provided. The **tool_args syntax unpacks the JSON object into keyword arguments.\n",
        "\n"
      ],
      "metadata": {
        "id": "Mc9xsgye2TdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Benefits of Function Calling APIs\n",
        "\n",
        "1. **Eliminates prompt engineering for structured responses** – No need to force the model to output JSON manually.\n",
        "2. **Uses standardized JSON Schema** – The same format used in API documentation applies seamlessly to AI interactions.\n",
        "3. **Allows mixed text and tool execution** – The model can decide whether a tool is necessary or provide a natural response.\n",
        "4. **Simplifies parsing logic** – Instead of handling inconsistent outputs, developers only check for tool_calls in the response.\n",
        "5. **Guarantees syntactically correct arguments** – The model automatically ensures arguments match the expected parameter format.\n",
        "\n",
        "# Conclusion\n",
        "Function calling APIs significantly improve the reliability of AI-agent interactions by enforcing structured execution. By defining tools with JSON Schema and letting the model determine when to use them, we build a more predictable and maintainable AI environment interface. In the next section, we will explore how to register these tools dynamically using decorators to further streamline agent development."
      ],
      "metadata": {
        "id": "vTg1sAPj2L3a"
      }
    }
  ]
}